[{"content":"TLDR; Building CI/CD pipelines for containers is not as daunting as it seems. For GitLab specifically, I have included a GitLab CI/CD configuration to automatically build and deploy your custom container images in the Artifacts section.\nDisclaimer: If you have not read DevAttackOps Part 1, you should start there. We will use the Cobalt Strike container we built in that post in following examples.\nWelcome to part 2 of the DevAttackOps series where I talk about all things regarding Red Team infrastructure automation. In DevAttackOps Part 1, I showed how it is possible to take a C2 framework and package it into a container image. In this post, I will talk about how you can expand on that and build out a CI/CD pipeline to automatically build and deploy those images to a container registry where they can be accessed programmatically.\nIf you work in IT in any capacity, you have heard the term \u0026ldquo;DevOps\u0026rdquo; or \u0026ldquo;Continuous Integration and Continuous Deployment\u0026rdquo; (CI/CD for short). These terms are the bread and butter for any junior engineer to throw on a resume and have absolutely zero clue what they actually mean (kidding, well only kinda). Today, I will walk you through what they mean to me as a Red Teamer and why you should learn how to integrate your Red Team\u0026rsquo;s infrastructure into a CI/CD pipeline.\nKey Terms CI/CD: a method to frequently deliver apps to customers by introducing automation into the stages of app development (Source: RedHat) Container Registry: a single place for your team to manage Docker images (Source: Google Cloud) Why Build a CI/CD Pipeline? If you are reading this, you clearly want to learn and do not want to be that junior engineer who loves putting buzzwords on their resume without actually understanding the concepts and technology behind them. Speaking of which, I should probably remove BlockChain from mine, but I digress. Let me convince you why you should care. In my mind, the reasons why you should care are the same as in DevAttackOps Part 1: repeatability and ease of use. However, I will add one more here: reducing complexity.\nRepeatability In a CI/CD pipeline, you have a single source of truth for building and deploying all your images. That means that you will never need to \u0026ldquo;take notes\u0026rdquo; on what build arguments you need to use to build a specific container image. Using a single, well-defined pipeline means that your builds will do the exact same thing each run and there is less room for human error.\nEase of Use Using a CI/CD pipeline means you have control over how you build and where you publish to. For containers, that means you can automatically deploy all container images to a registry and use one line of code to pull that image down and run that container. This is very powerful. It allows anyone with any skill level to use your container images (as long as they can authenticate to your registry).\nReduce Complexity As a Red Teamer, I already have a lot I have to learn and remember. The last thing I want to remember is how to install a specific software on a server. I leave that up to the sysadmins of the world. You all are the real heroes. In using a CI/CD pipeline, I can use my single source of truth for building all my software and \u0026ldquo;automate away the minutiae\u0026rdquo; of infrastructure work so I can focus on the value-add activities of my job.\nBuilding the Pipeline As we go through building out this CI/CD pipeline, I want to remind you that this is not the only solution. There are may different ways to skin the cat (sorry I hate that phrase too). I want to provide a tangible example for you to try this on your own. In doing so, I will walk you through how you build out a CI/CD pipeline using a GitLab repository as the source and GitLab container registry as the container registry. Both are FREE, so you have no excuses to not build this yourself. However, you can just as easily acomplish the same goal using GitHub Actions and a container registry like Amazon Elastic Container Registry (ECR). Notice my theme of abstracting away the \u0026ldquo;use case\u0026rdquo; from the platform, this will come up way more often in the future.\nCreating the Repository Before you can go building your pipeline, we need to think through how we want to organize our code. What I have found is the best way to manage all the container definitions is by having one single repository that has a folder for each container. Let\u0026rsquo;s get started by creating the repository.\nmkdir container-ci_cd cd container-ci_cd git init Adding your First Container Definition Inside the new repository, create a cobaltstrike folder to hold our Cobalt Strike Dockerfile.\nmkdir cobaltstrike touch Dockerfile Using your favorite Integrated Development Environment (IDE) or text editor, you can now edit the Dockerfile you just created to hold the same Dockerfile definition you use to build Cobalt Strike. That is really all you need to do! We will add more containers in a bit.\nCreating a Basic Pipeline Since we are using GitLab to handle the pipeline, to integrate it with the GitLab CI/CD, all we need to do is add a .gitlab-ci.yml file in the root of our repository (as per the GitLab documentation). The .gitlab-ci.yml file is going to be our workhorse. It will hold all the build and deploy commands for our container images.\nWhen you look at some of the examples on the web of how to structure the .gitlab-ci.yml file, it can get confusing, frustrating, and even scary. However, the one thing to remember is that this file is just a fancy way to run shell commands on a computer that GitLab will spin up whenever you commit to your repository. With that, let\u0026rsquo;s look at a simple example of the base .gitlab-ci.yml file we will use for our repository.\nbuild: image: docker:19.03.12 stage: build services: - docker:19.03.12-dind before_script: - echo \u0026#34;Before\u0026#34; script: - echo \u0026#34;During\u0026#34; In this configuration, we are telling GitLab exactly how to run the \u0026ldquo;build\u0026rdquo; stage of our pipeline. This is the default stage. You can define other stages as well. Within that \u0026ldquo;build\u0026rdquo; stage, we are telling GitLab to use the docker:19.03.12 base container image (yes container-ception, we are using a container to build our containers). You will also see that we are using a \u0026ldquo;service\u0026rdquo; called docker:19.03.12-dind which now tells GitLab that we want to use the Docker-in-Docker image to execute the container-building commands. The way I think of the services definition is as the \u0026ldquo;tools\u0026rdquo; we need to successfully run our commands. On a traditional server, in order for us to build containers, we would need to install Docker onto that system. However, with GitLab\u0026rsquo;s pipeline, we can just use another container (with all required tools we need already installed on it) to run each command. If we commit that file up to GitLab, we see that the job will pull back that container image and run our commands.\nI realize that may have lost you since you may still need some more clarification on service definitions. You may want to check out GitLab\u0026rsquo;s documentation to fully understand their concept of \u0026ldquo;services.\u0026rdquo; They do a great job explaining the technical details.\nUnderstanding the Container Registry Sweet, so now we are using GitLab\u0026rsquo;s CI/CD to execute commands whenever we make changes to the repository. Now we want to make it do something useful, like build our Cobalt Strike container. Since we already know the command to build the container, we can use that as the starting point. However, since we are going to be deploying the container image up to GitLab\u0026rsquo;s container registry, we need to understand how the registry works. In looking at the GitLab Container Registry documentation, it seems like a standard registry. The only caveat here is that in order to use the registry, we need to use a \u0026ldquo;personal access token\u0026rdquo; to sign into the registry before we can interact with it. Before trying to use all these new tools together it is important to understand each tool, one at a time.\nTo start using the registry, we need to generate a personal access token. You can do this by going to your user preferences, selecting \u0026ldquo;Access Tokens\u0026rdquo;, and generating a new token with the scopes write_registry and read_registry.\nOnce you hit create, you should get a token that starts with glpat-. This will allow you to login to the GitLab registry using the Docker CLI.\ndocker login -u ezra-buckingham -p glpat-\u0026lt;...redacted...\u0026gt; registry.gitlab.com Now, we can use the Cobalt Strike Dockerfile we created in the cobaltstrike folder earlier, build it with a tag that points to our new repository called container-ci_cd, and push it up to that repository\u0026rsquo;s registry. Note that ezragit refers to my GitLab organization and container-ci_cd refers to the repository that will be my registry.\ndocker build -t registry.gitlab.com/ezragit/container-ci_cd/cobaltstrike:latest --build-arg COBALTSTRIKE_LICENSE=$COBALTSTRIKE_LICENSE ./cobaltstrike docker push registry.gitlab.com/ezragit/container-ci_cd/cobaltstrike:latest After running those commands, we can see the Cobalt Strike container in our GitLab registry.\nTo use that container image, any user that has access to that repository can create their own \u0026ldquo;personal access token\u0026rdquo; with the registry_read scope and can use the same docker login CLI command to login to registry.gitlab.com and then pull down the container image.\ndocker run registry.gitlab.com/ezragit/container-ci_cd/cobaltstrike:latest Using the Pipeline to Build and Push the Image We now have an understanding of the registry and a basic implementation of the CI/CD pipeline. Now let\u0026rsquo;s combine the two. If we take our .gitlab-ci.yml file and copy the commands we just ran into it, everything should work right? Well not exactly. Since the Cobalt Strike container takes in a build-arg, we need to somehow pass that into the CI/CD job. This is where GitLab CI/CD variables come into play. Inside the CI/CD settings of your repository, you can store secrets like the COBALTSTRIKE_LICENSE and pull them into the job.\nHowever, to pull that secret into the job, you must explicitly put that variable into the variables block so that it can be passed into the build commands.\nbuild: image: docker:19.03.12 stage: build services: - docker:19.03.12-dind variables: COBALTSTRIKE_LICENSE: $COBALTSTRIKE_LICENSE script: - docker build -t registry.gitlab.com/ezragit/container-ci_cd/cobaltstrike:latest --build-arg COBALTSTRIKE_LICENSE=$COBALTSTRIKE_LICENSE ./cobaltstrike - docker push registry.gitlab.com/ezragit/container-ci_cd/cobaltstrike:latest Now that we have this, we can commit and push these changes to try out our fancy new build command. But this is not enough. If we push this and see the results, we get an error when we try to push the image.\nThis is because we need to authenticate to the registry. What is cool is that we do not need to generate any credentials. We can use the secrets embedded in the runner to dynamically authenticate to the registry (depending on what user made the change). We can do this by using the GitLab default secrets of CI_REGISTRY_USER and CI_REGISTRY_PASSWORD in a docker login command. While we are at it, we should also remove some of the hardcoded values as well. We can also leverage the CI_REGISTRY to dynamically point to the registry and even create a new variable with the full path to our registry and then reference that in the docker build and push.\nbuild: image: docker:19.03.12 stage: build services: - docker:19.03.12-dind variables: CI_REGISTRY_PATH: $CI_REGISTRY/ezragit/container-ci_cd COBALTSTRIKE_LICENSE: $COBALTSTRIKE_LICENSE before_script: - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY script: - docker build -t $CI_REGISTRY_PATH/cobaltstrike:latest --build-arg COBALTSTRIKE_LICENSE=$COBALTSTRIKE_LICENSE ./cobaltstrike - docker push $CI_REGISTRY_PATH/cobaltstrike:latest When we push these changes, we can see the job completes successfully and automatically builds and deploys our image to our private registry!\nExpanding Capabilities Now that we have a way to automate this, what if we wanted to add another image to our registry? It\u0026rsquo;s easy! Let\u0026rsquo;s build Sliver into our registry. First, we need a new folder for sliver so we can hold our Dockerfile.\nmkdir sliver touch Dockerfile We can (using skills learned in Part 1) build out that Dockerfile to build our Sliver container image.\nFROM debian:stable-slim RUN apt-get update \\ \u0026amp;\u0026amp; apt-get -y install git wget zip tar file mingw-w64 WORKDIR /opt/sliver RUN wget https://github.com/BishopFox/sliver/releases/download/v1.5.16/sliver-server_linux \\ \u0026amp;\u0026amp; mv sliver-server_linux sliver-server \\ \u0026amp;\u0026amp; chmod +x ./sliver-server WORKDIR /opt/sliver EXPOSE 3333 443 80 53/udp ENTRYPOINT [ \u0026#34;./sliver-server\u0026#34; ] Then we can add the commands needed to build and push the image directly into our .gitlab-ci.yml file.\nbuild: image: docker:19.03.12 stage: build services: - docker:19.03.12-dind variables: CI_REGISTRY_PATH: $CI_REGISTRY/ezragit/container-ci_cd COBALTSTRIKE_LICENSE: $COBALTSTRIKE_LICENSE before_script: - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY script: - docker build -t $CI_REGISTRY_PATH/cobaltstrike:latest --build-arg COBALTSTRIKE_LICENSE=$COBALTSTRIKE_LICENSE ./cobaltstrike - docker push $CI_REGISTRY_PATH/cobaltstrike:latest - docker build -t $CI_REGISTRY_PATH/sliver:latest ./sliver - docker push $CI_REGISTRY_PATH/sliver:latest And yes, it is that easy to build your own CI/CD pipeline to build and deploy container images to a private container registry.\nThe Problems with the Solution We have an awesome start to what is becoming a badass little CI/CD pipeline, but we can do better. There are 2 big problems with what we have come up with: failure tracing and speed (there are more, but topic for another time as it gets deeper into the weeds).\nFailure Tracing In our current solution, if any of the builds or pushes fail, the rest of the pipeline fails. This makes it difficult to track down which container image failed to build and what that failure was.\nSpeed Since all of our commands run in sequence, each build needs to wait until the previous one finishes to start building.\nImproving the Solution We can alleviate both of those problems by splitting out each container build into their own build step, but tie them both into the parent \u0026ldquo;build\u0026rdquo; step. We can do this, by defining the parent \u0026ldquo;build\u0026rdquo; step inside of the stages list and then use the stage key in each container build to be set to \u0026ldquo;build\u0026rdquo;. Since some of that results in a duplication of code (which if you ask me, one of the world\u0026rsquo;s biggest problems is code duplication), we can use anchors and aliases. If you are unfamiliar with anchors and aliases in YAML, you should learn more about them in this blog post. For our CI/CD configuration, we can create an anchor for a \u0026ldquo;global\u0026rdquo; configuration and then reference that anchor as an alias in each build.\nimage: docker:19.03.12 stages: - build # Global Job Config for all container builds (include build arg variables here) .job_configuration_template: \u0026amp;job_configuration stage: build services: - docker:19.03.12-dind variables: CI_REGISTRY_PATH: $CI_REGISTRY/ezragit/container-ci_cd COBALTSTRIKE_LICENSE: $COBALTSTRIKE_LICENSE before_script: - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY # Actual Builds build_cobaltstrike: \u0026lt;\u0026lt;: *job_configuration script: - docker build -t $CI_REGISTRY_PATH/cobaltstrike:latest --build-arg COBALTSTRIKE_LICENSE=$COBALTSTRIKE_LICENSE ./cobaltstrike - docker push $CI_REGISTRY_PATH/cobaltstrike:latest build_sliver: \u0026lt;\u0026lt;: *job_configuration script: - docker build -t $CI_REGISTRY_PATH/sliver:latest ./sliver - docker push $CI_REGISTRY_PATH/sliver:latest With this new and improved CI/CD configuration, when we push to this repository, we will see logically each container build split out into it\u0026rsquo;s own \u0026ldquo;job\u0026rdquo;. This allows us to see who the \u0026ldquo;trouble child\u0026rdquo; is if the pipeline fails. Not to mention, now all the containers can be built in parallel (which since we are on the free tier of GitLab, this means we can keep tinkering with CI/CD without paying for the next tier).\nAnd that\u0026rsquo;s it! You now have your own CI/CD pipeline for your container images. Now that we have a centralized place for all our containers, we can deploy them wherever we would like\u0026hellip; I wonder how we might do that in an easy way\u0026hellip; stay tuned.\nArtifacts Here is the .gitlab-ci.yml file I use to build all my containers (to add more, I just copy and past the build config and change a few of the values).\nimage: docker:19.03.12 stages: - build # Global Job Config for all container builds (include build arg variables here) .job_configuration_template: \u0026amp;job_configuration stage: build services: - docker:19.03.12-dind variables: CI_REGISTRY_PATH: $CI_REGISTRY/ezragit/container-ci_cd COBALTSTRIKE_LICENSE: $COBALTSTRIKE_LICENSE before_script: - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY # Actual Builds build_cobaltstrike: \u0026lt;\u0026lt;: *job_configuration script: - docker build -t $CI_REGISTRY_PATH/cobaltstrike:latest --build-arg COBALTSTRIKE_LICENSE=$COBALTSTRIKE_LICENSE ./cobaltstrike - docker push $CI_REGISTRY_PATH/cobaltstrike:latest build_sliver: \u0026lt;\u0026lt;: *job_configuration script: - docker build -t $CI_REGISTRY_PATH/sliver:latest ./sliver - docker push $CI_REGISTRY_PATH/sliver:latest ","permalink":"https://ezrabuckingham.com/blog/containers-ci_cd/","summary":"TLDR; Building CI/CD pipelines for containers is not as daunting as it seems. For GitLab specifically, I have included a GitLab CI/CD configuration to automatically build and deploy your custom container images in the Artifacts section.\nDisclaimer: If you have not read DevAttackOps Part 1, you should start there. We will use the Cobalt Strike container we built in that post in following examples.\nWelcome to part 2 of the DevAttackOps series where I talk about all things regarding Red Team infrastructure automation.","title":"DevAttackOps: Container CI/CD Pipelines (Part 2)"},{"content":"TLDR; Building containers for Red Team applications is easy. I have included a Cobalt Strike Dockerfile for you in the Artifacts section.\nSo here is my first actual blog post. In this series, I am going to talk about how Red Teams can use the same tools used by developers to both simplify Red Team infrastructure and generally make your life easier. In Part 1, I will be talking about why Red Teams should use containers in their workflows. As our European friends say, \u0026ldquo;Let\u0026rsquo;s get stuck in!\u0026rdquo;\nWhy Containerize? Here is a question that I kept asking myself: what the hell is all the rage about containers? Honestly, it is a great question! As a Red Teamer, here are two big reasons why you should care (yes there are likely more, but here are the reasons from my perspective):\nRepeatability Red Teams are in the interesting category of teams since we are often deploying infrastructure into a variety of places. In doing so, we need to fight with various configurations that may be baked into each cloud provider\u0026rsquo;s OS images. This is not that big of a deal, but when you do run into a stupid configuration that is blocking your software from installing, it can be a huge time sink to try and determine what is going wrong. However, when you package all your code into a container, you know that no matter where you deploy that container to, it will always work the same way.\nEase of Use Have you ever had someone come up to you and complain that their install of insert-software-name is not working? Or have you ever onboarded a new team member and told them to just go play around with Cobalt Strike just to get familiar with Command and Control (C2) frameworks? I am willing to bet you have answered yes to one of these questions. If you have, then you can benefit from containers. When you build a container, instead of directing that person to the documentation or a Stack Overflow post of all the ways a Cobalt Strike install can fail, you could just containerize the solution and give that person the Dockerfile or a registry to pull from and they are all set.\nKey Terms Great, maybe I have convinced you about containerizing your Red Team tools! Before diving into \u0026ldquo;how\u0026rdquo; you do this, I need to define some key terms so I do not lose you in the process:\nDockerfile: a text document that contains all the commands a user could call on the command line to assemble an image (From Docker official documentation here) Buildtime Arguments: dynamic arguments passed into Docker at the container \u0026ldquo;build time\u0026rdquo; to allow for more control over a container image when building Runtime Arguments: arguments that are passed into the docker run command and then passed as arguments to the container execution point Building your First Container Wow, that was boring. Now for the fun stuff!\nLet\u0026rsquo;s work on building your first container. For example\u0026rsquo;s sake, let\u0026rsquo;s build a Cobalt Strike container. Before we begin, I will assume you have a very basic understanding of how Docker works. And also, since my team uses Debian-based operating systems, I will be making my example with debian:stable-slim as the base image.\nAutomating the Cobalt Strike Install Before we can build a container for Cobalt Strike, we need to automate the commands to install all the dependencies, download the Cobalt Strike package, extract the package, and run the update script which will also license the product. Let\u0026rsquo;s break each step down\u0026hellip;\nInstall All Dependencies Since Cobalt Strike is Java-based, we need to make sure that we have Java installed in the container. Additionally, there are other dependencies that we will want to install in the container to make sure everything works as intended. Since Debian uses apt, we can install the latest Java package and other packages using the following command:\napt-get install --no-install-recommends -y ca-certificates curl expect git gnupg iproute2 openjdk-11-jdk wget Download the Cobalt Strike Package Great, now that we have all the required dependencies, we can download the package from their website. This should be a simple wget request, right? Well not exactly\u0026hellip;\nTo download Cobalt Strike, go to https://download.cobaltstrike.com/download and enter your license key. You will be redirected to another page where you select your operating system and then download the package. This is a little challenging considering when you enter your license key, you get a token that is part of the download URL. In order to capture that token, you can make the initial GET request with your license key as a query parameter and use some Bash magic to extract that token. In this example, I have set the COBALTSTRIKE_LICENSE environment variable which allows me to dynamically reference it in the initial curl request.\nexport COBALTSTRIKE_LICENSE=\u0026#34;\u0026lt;cobaltstrike_license\u0026#34; curl -s https://download.cobaltstrike.com/download -d \u0026#34;dlkey=${COBALTSTRIKE_LICENSE}\u0026#34; | grep \u0026#39;href=\u0026#34;/downloads/\u0026#39; | cut -d \u0026#39;/\u0026#39; -f3 With this curl command, we get the token that we need to include in the download URL. However, just getting the token does us no good. We need to save the token and use it in a subsequent request. We can do this by exporting the results of the curl command above to an environment variable by wrapping that command in export TOKEN=$(\u0026lt;curl-command\u0026gt;).\nexport TOKEN=$(curl -s https://download.cobaltstrike.com/download -d \u0026#34;dlkey=${COBALTSTRIKE_LICENSE}\u0026#34; | grep \u0026#39;href=\u0026#34;/downloads/\u0026#39; | cut -d \u0026#39;/\u0026#39; -f3) Now that we have the token, all we need to do is make a wget to get the cobaltstrike-dist.tgz file and use Bash expansion to expand that token in the wget request.\nwget https://download.cobaltstrike.com/downloads/${TOKEN}/latest46/cobaltstrike-dist.tgz Extracting and Updating Cobalt Strike Now that we have the package, we can use tar to extract the package.\ntar zxf cobaltstrike-dist.tgz However, before we can run the teamserver, we need to run the update script to license the package we just downloaded. Since the update script will expect us to provide the license key via standard input, we can use an echo command to give it the key.\necho ${COBALTSTRIKE_LICENSE} | ./update Creating the Dockerfile Great, now we have a working version of Cobalt Strike installed! Since a Dockerfile can take and run Bash commands to setup a container image, we can take everything we just learned and put it into a Dockerfile. To start building our first container, run the following commands:\nmkdir cobaltstrike cd cobaltstrike touch Dockerfile Using Buildtime Arguments Using our newly created directory and file, we now can start building out the Dockerfile. In the example above, I exported the COBALTSTRIKE_LICENSE as an environment variable. But how the hell can I mimic that functionality with Docker so I do not need to hardcode my license key into the Dockerfile? This is where buildtime arguments come in. Using a buildtime argument, we will pass the Cobalt Strike license using the build-arg flag so that when we build the container, we have a fully licensed version of Cobalt Strike. The way we do this is by defining a ARG in the Dockerfile and then pass that ARG at build time.\nFROM debian:stable-slim # Required Arguments ARG COBALTSTRIKE_LICENSE Now we can use that same environment variable called COBALTSTRIKE_LICENSE we set earlier to pass in the license key.\ndocker build -t cobaltstrike:latest --build-arg COBALTSTRIKE_LICENSE=$COBALTSTRIKE_LICENSE . Converting the Manual Commands Now we need to convert all the manual commands we ran earlier into Dockerfile commands. Thankfully, we can use the RUN command in our Dockerfile to just copy and paste all the commands we ran earlier.\n# Install all dependencies RUN apt-get update \u0026amp;\u0026amp; \\ apt-get install --no-install-recommends -y ca-certificates curl expect git gnupg iproute2 openjdk-11-jdk wget \u0026amp;\u0026amp; \\ apt-get clean \u0026amp;\u0026amp; \\ rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* \u0026amp;\u0026amp; \\ update-java-alternatives -s java-1.11.0-openjdk-amd64 # Install and update Cobalt Strike RUN echo \u0026#34;COBALTSTRIKE_LICENSE: ${COBALTSTRIKE_LICENSE}\u0026#34; \u0026amp;\u0026amp; \\ export TOKEN=$(curl -s https://download.cobaltstrike.com/download -d \u0026#34;dlkey=${COBALTSTRIKE_LICENSE}\u0026#34; | grep \u0026#39;href=\u0026#34;/downloads/\u0026#39; | cut -d \u0026#39;/\u0026#39; -f3) \u0026amp;\u0026amp; \\ cd /opt \u0026amp;\u0026amp; \\ wget https://download.cobaltstrike.com/downloads/${TOKEN}/latest46/cobaltstrike-dist.tgz \u0026amp;\u0026amp; \\ tar zxf cobaltstrike-dist.tgz \u0026amp;\u0026amp; \\ rm /etc/ssl/certs/java/cacerts \u0026amp;\u0026amp; \\ update-ca-certificates -f \u0026amp;\u0026amp; \\ cd /opt/cobaltstrike \u0026amp;\u0026amp; \\ echo ${COBALTSTRIKE_LICENSE} | ./update \u0026amp;\u0026amp; \\ mkdir /opt/cobaltstrike/mount Pro Tip: If you think you have errors in your Dockerfile, run the build command we defined earlier. This will tell you exactly where you have issues.\nExposing Ports One of the most difficult concepts in Docker is networking. Because a container is an entire operating system inside an operating system, the container has no knowledge of the base operating system\u0026rsquo;s networking configuration. Nor should it. Because of this, we need to tell the container only what it needs to know. For example, what ports should be exposed to the host operating system.\nFor Cobalt Strike, the most commonly used ports are:\n50050/TCP: teamserver connection 443/TCP: HTTPS C2 80/TCP: HTTP C2 53/UDP: DNS C2 Because a container is a self-contained operating system (pardon my pun), we must use the EXPOSE function in our Dockerfile to tell the container to explicitly allow specific ports to be accessed. Doing this in a Dockerfile is very easy.\nEXPOSE 50050 443 80 53/udp By using the EXPOSE definition above, we are explicitly telling the container to allow networking connections to happen on ports 50050/TCP, 443/TCP, 80/TCP, and 53/UDP.\nSetting the Entrypoint The purpose of our container is to be a standalone implementation of a Cobalt Strike teamserver. Up to this point, we have Cobalt Strike being installed into the container and we have told the container what ports should be accessible, but we still have yet to run the teamserver command to stand up the actual teamserver. In Docker, we can use the ENTRYPOINT function to tell the container what program to start when the container starts. This means that when I run this container, I want to have it automatically run the teamserver command.\nENTRYPOINT [\u0026#34;./teamserver\u0026#34;] In defining this ENTRYPOINT, the container will now boot and immediately execute that command. However, keep in mind that if the teamserver command exits or errors out, the container will stop. Whenever the ENTRYPOINT command exits, the entire container will stop. This is typically a gotcha with most developers who start tinkering around with containers.\nAlso, for those of you who have played with containers before, you probably know that there is also the CMD command that also exists. The key difference is that when you use CMD and pass in runtime arguments, you need to explicitly tell the container what base binary you want to run (essentially overwriting that CMD in the Dockerfile). If you want to learn more, here is a great blog post that covers the key differences.\nPutting it all Together Wow! You are still reading this? Kudos to you for being dedicated to wanting to learn! Now that we have everything, we need to actually build the container. Let\u0026rsquo;s put it all together and build this damn thing! If we put all the commands above together, we get a Dockerfile that looks like this:\nFROM debian:stable-slim # Required Arguments ARG COBALTSTRIKE_LICENSE # Install all dependencies RUN apt-get update \u0026amp;\u0026amp; \\ apt-get install --no-install-recommends -y ca-certificates curl expect git gnupg iproute2 openjdk-11-jdk wget \u0026amp;\u0026amp; \\ apt-get clean \u0026amp;\u0026amp; \\ rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* \u0026amp;\u0026amp; \\ update-java-alternatives -s java-1.11.0-openjdk-amd64 # Install and update Cobalt Strike RUN echo \u0026#34;COBALTSTRIKE_LICENSE: ${COBALTSTRIKE_LICENSE}\u0026#34; \u0026amp;\u0026amp; \\ export TOKEN=$(curl -s https://download.cobaltstrike.com/download -d \u0026#34;dlkey=${COBALTSTRIKE_LICENSE}\u0026#34; | grep \u0026#39;href=\u0026#34;/downloads/\u0026#39; | cut -d \u0026#39;/\u0026#39; -f3) \u0026amp;\u0026amp; \\ cd /opt \u0026amp;\u0026amp; \\ wget https://download.cobaltstrike.com/downloads/${TOKEN}/latest46/cobaltstrike-dist.tgz \u0026amp;\u0026amp; \\ tar zxf cobaltstrike-dist.tgz \u0026amp;\u0026amp; \\ rm /etc/ssl/certs/java/cacerts \u0026amp;\u0026amp; \\ update-ca-certificates -f \u0026amp;\u0026amp; \\ cd /opt/cobaltstrike \u0026amp;\u0026amp; \\ echo ${COBALTSTRIKE_LICENSE} | ./update \u0026amp;\u0026amp; \\ mkdir /opt/cobaltstrike/mount # Expose the ports and run it WORKDIR /opt/cobaltstrike EXPOSE 50050 443 80 53/udp ENTRYPOINT [\u0026#34;./teamserver\u0026#34;] And with that Dockerfile in our cobaltstrike directory, we can now build the container image.\ndocker build -t cobaltstrike:latest --build-arg COBALTSTRIKE_LICENSE=$COBALTSTRIKE_LICENSE . Using the Container (without a Malleable C2 Profile) We have a new fancy schmancy Cobalt Strike container. Now we want to use it. This is where we need to use the docker run command.\ndocker run -it cobaltstrike 192.168.1.1 password With the command above, we are essentially running the following command ./teamserver 192.168.1.1 password, but it is all in a container. This means that it is all running in its own operating system. The -it flag starts the container in interactive mode. This allows us to see the standard output of the container. We can use ctrl + c on that process to kill the container.\nRemember what I said earlier, the hardest part to Docker is networking. Although we are running a container, other computers have no idea that a container is running and listening on the ports we had EXPOSE\u0026rsquo;d. To fix this, we need to define port proxies in our docker run command. This will tell the host operating system what ports it should listen to and what ports it should map to the container ports. This can be accomplished using the -p \u0026lt;host_port\u0026gt;:\u0026lt;container_port\u0026gt; syntax.\ndocker run -it -p \u0026#34;50050:50050/tcp\u0026#34; -p \u0026#34;443:443/tcp\u0026#34; -p \u0026#34;80:80/tcp\u0026#34; -p \u0026#34;53:53/udp\u0026#34; cobaltstrike 192.168.1.1 password From here, we now have a full Cobalt Strike container listening on all interfaces of your host operating system!\nUsing the Container (with a Malleable C2 Profile) All of that was super cool, right? But wait a minute\u0026hellip; what the hell do I do if I want to use a Malleable C2 profile with the container? This is where bind mounts come into play. We need to tell the container to mount to the host operating system to allow the container to access files on the host. Keep in mind, doing so may have security implications. Make sure you understand those implications before doing this with all of your containers.\nInside the run command we can create a bind mount using the --mount parameter. Let\u0026rsquo;s say you already have a Malleable C2 profile created called c2.profile and it\u0026rsquo;s located in the cobaltstrike directory you created earlier. In order to use that profile in the container, you need to create a bind mound to the cobaltstrike directory in the container and then reference that profile (that now exists in the container\u0026rsquo;s target directory) in the entrypoint.\ndocker run -it --mount type=bind,source=\u0026#34;$(pwd)\u0026#34;,target=/opt/cobaltstrike/mount -p \u0026#34;50050:50050/tcp\u0026#34; -p \u0026#34;443:443/tcp\u0026#34; -p \u0026#34;80:80/tcp\u0026#34; -p \u0026#34;53:53/udp\u0026#34; cobaltstrike 192.168.1.1 password /opt/cobaltstrike/mount/c2.profile With that, you have everything you now need to build and run your very own Cobalt Strike container.\nDemonstration With everything we have learned, we can now build the container image.\nAfter building the image, we can run the container with the bind mount to use our custom C2 profile.\nWe see the container has booted properly. Now we can use the host operating system\u0026rsquo;s IP address to connect to the container.\nAfter we hit connect, we become connected to our containerized version of Cobalt Strike!\nWhat\u0026rsquo;s Next? Next week, I will release a blog post on how we can leverage a container registry to take this container image and allow other operators use the prebuilt image. We will use one line of code to pull that container down and run it! Stay tuned!\nArtifacts The Dockerfile:\nFROM debian:stable-slim # Required Arguments ARG COBALTSTRIKE_LICENSE # Install all dependencies RUN apt-get update \u0026amp;\u0026amp; \\ apt-get install --no-install-recommends -y ca-certificates curl expect git gnupg iproute2 openjdk-11-jdk wget \u0026amp;\u0026amp; \\ apt-get clean \u0026amp;\u0026amp; \\ rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* \u0026amp;\u0026amp; \\ update-java-alternatives -s java-1.11.0-openjdk-amd64 # Install and update Cobalt Strike RUN echo \u0026#34;COBALTSTRIKE_LICENSE: ${COBALTSTRIKE_LICENSE}\u0026#34; \u0026amp;\u0026amp; \\ export TOKEN=$(curl -s https://download.cobaltstrike.com/download -d \u0026#34;dlkey=${COBALTSTRIKE_LICENSE}\u0026#34; | grep \u0026#39;href=\u0026#34;/downloads/\u0026#39; | cut -d \u0026#39;/\u0026#39; -f3) \u0026amp;\u0026amp; \\ cd /opt \u0026amp;\u0026amp; \\ wget https://download.cobaltstrike.com/downloads/${TOKEN}/latest46/cobaltstrike-dist.tgz \u0026amp;\u0026amp; \\ tar zxf cobaltstrike-dist.tgz \u0026amp;\u0026amp; \\ rm /etc/ssl/certs/java/cacerts \u0026amp;\u0026amp; \\ update-ca-certificates -f \u0026amp;\u0026amp; \\ cd /opt/cobaltstrike \u0026amp;\u0026amp; \\ echo ${COBALTSTRIKE_LICENSE} | ./update \u0026amp;\u0026amp; \\ mkdir /opt/cobaltstrike/mount # Expose the ports and run it WORKDIR /opt/cobaltstrike EXPOSE 50050 443 80 53/udp ENTRYPOINT [\u0026#34;./teamserver\u0026#34;] The build command:\ndocker build -t cobaltstrike:latest --build-arg COBALTSTRIKE_LICENSE=$COBALTSTRIKE_LICENSE . The run command (without Malleable C2):\ndocker run -it -p \u0026#34;50050:50050/tcp\u0026#34; -p \u0026#34;443:443/tcp\u0026#34; -p \u0026#34;80:80/tcp\u0026#34; -p \u0026#34;53:53/udp\u0026#34; cobaltstrike 192.168.1.1 password The run command (with Malleable C2):\ndocker run -it --mount type=bind,source=\u0026#34;$(pwd)\u0026#34;,target=/opt/cobaltstrike/mount -p \u0026#34;50050:50050/tcp\u0026#34; -p \u0026#34;443:443/tcp\u0026#34; -p \u0026#34;80:80/tcp\u0026#34; -p \u0026#34;53:53/udp\u0026#34; cobaltstrike 192.168.1.1 password /opt/cobaltstrike/mount/c2.profile ","permalink":"https://ezrabuckingham.com/blog/containerizing-red-team-infra/","summary":"TLDR; Building containers for Red Team applications is easy. I have included a Cobalt Strike Dockerfile for you in the Artifacts section.\nSo here is my first actual blog post. In this series, I am going to talk about how Red Teams can use the same tools used by developers to both simplify Red Team infrastructure and generally make your life easier. In Part 1, I will be talking about why Red Teams should use containers in their workflows.","title":"DevAttackOps: Containerizing Red Team Infrastructure (Part 1)"},{"content":"Welcome! Welcome to the first installment of the Ezra Buckingham blog! I started to realize that I have done some interesting research (I am still an imposter so bear with me) and now want to share some of that research with the world. Stay tuned for some hopefully interesting research!\n","permalink":"https://ezrabuckingham.com/blog/welcome-to-the-blog/","summary":"Welcome! Welcome to the first installment of the Ezra Buckingham blog! I started to realize that I have done some interesting research (I am still an imposter so bear with me) and now want to share some of that research with the world. Stay tuned for some hopefully interesting research!","title":"Welcome to the Blog!"},{"content":"I am a security researcher and current Red Team Operator.\n","permalink":"https://ezrabuckingham.com/about-me/","summary":"search","title":"About Me"}]